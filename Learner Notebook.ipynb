{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network from Scratch in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Introduction and Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nn_utils\n",
    "%matplotlib inline\n",
    "\n",
    "print('TensorFlow Version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Initializing Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = NeuralNewtwork(10,100,11)\n",
    "#10 features for each example\n",
    "#11 classes for each example\n",
    "#100 unit in the hidden layer\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        self.L = len(layers)\n",
    "        self.num_features = layers[0]\n",
    "        self.num_classes = layers[-1]\n",
    "        \n",
    "        self.W = {}\n",
    "        self.b = {}\n",
    "        \n",
    "        self.dW = {}\n",
    "        self.db = {}\n",
    "        \n",
    "        self.setup()\n",
    "        \n",
    "    def setup(self):\n",
    "        # Your code here\n",
    "        for i in range(1, self.L):\n",
    "            self.W[i] = tf.Variable(tf.random.normal(shape=(self.layers[i],self.layers[i-1])))\n",
    "            self.b[i] = tf.Variable(tf.random.normal(shape=(self.layers[i],1)))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def forward_pass(self, X):\n",
    "        # Your code here\n",
    "        A = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "        for i in range(1, self.L):\n",
    "            Z = tf.matmul(A,tf.transpose(self.W[i])) + tf.transpose(self.b[i])\n",
    "            if i != self.L-1:\n",
    "                A = tf.nn.relu(Z)\n",
    "            else:\n",
    "                    A = Z\n",
    "        return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Computing Loss and Updating Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    # Your code here\n",
    "    def compute_loss(self, A, Y):\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(Y,A)\n",
    "        return tf.reduce_mean(loss)\n",
    "    \n",
    "    \n",
    "    def update_params(self, lr):\n",
    "        for i in range(1,self.L):\n",
    "            self.W[i].assign_sub(lr * self.dW[i])\n",
    "            self.b[i].assign_sub(lr * self.db[i])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5: Predict and Info Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def predict(self, X):\n",
    "        # Your code here\n",
    "        A = self.forward_pass(X)\n",
    "        return tf.argmax(tf.nn.softmax(A), axis=1)\n",
    "    \n",
    "    def info(self):\n",
    "        num_params = 0\n",
    "        for i in range(1, self.L):\n",
    "            num_params += self.W[i].shape[0] * self.W[i].shape[1]\n",
    "            num_params += self.b[i].shape[0]\n",
    "        print('Input Features:', self.num_features)\n",
    "        print('Number of Classes:', self.num_classes)\n",
    "        print('Hidden Layers:')\n",
    "        print('--------------')\n",
    "        for i in range(1, self.L-1):\n",
    "            print('Layer {}, Units {}'.format(i, self.layers[i]))\n",
    "        print('--------------')\n",
    "        print('Number of parameters:', num_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6: Training on Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def train_on_batch(self, X, Y, lr):\n",
    "        # Your code here\n",
    "        X = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "        Y = tf.convert_to_tensor(Y, dtype=tf.float32)\n",
    "        \n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            A = self.forward_pass(X)\n",
    "            loss = self.compute_loss(A, Y)\n",
    "        for i in range(1, self.L):\n",
    "            self.dW[i] = tape.gradient(loss, self.W[i])\n",
    "            self.db[i] = tape.gradient(loss, self.b[i])\n",
    "        del tape\n",
    "        self.update_params(lr)\n",
    "        return loss.numpy()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 7: Training on Complete Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def train(self, x_train, y_train, x_test, y_test, epochs, steps_per_epoch, batch_size, lr):\n",
    "        # Your code here\n",
    "        history = {\n",
    "            'val_loss':[],\n",
    "            'train_loss':[],\n",
    "            'val_acc':[]\n",
    "        }\n",
    "        \n",
    "        for e in range(0, epochs):\n",
    "            epoch_train_loss = 0.\n",
    "            print('Epoch{}'.format(e), end='.')\n",
    "            for i in range(0, steps_per_epoch):\n",
    "                x_batch = x_train[i*batch_size:(i+1)*batch_size]\n",
    "                y_batch = y_train[i*batch_size:(i+1)*batch_size]\n",
    "                \n",
    "                batch_loss = self.train_on_batch(x_batch, y_batch,lr)\n",
    "                epoch_train_loss += batch_loss\n",
    "                \n",
    "                if i%int(steps_per_epoch/10) == 0:\n",
    "                    print(end='.')\n",
    "                    \n",
    "            history['train_loss'].append(epoch_train_loss/steps_per_epoch)\n",
    "            val_A = self.forward_pass(x_test)\n",
    "            val_loss = self.compute_loss(val_A, y_test).numpy()\n",
    "            history['val_loss'].append(val_loss)\n",
    "            val_preds = self.predict(x_test)\n",
    "            val_acc =    np.mean(np.argmax(y_test, axis=1) == val_preds.numpy())\n",
    "            history['val_acc'].append(val_acc)\n",
    "            print('Val acc:',val_acc)\n",
    "        return history\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 8: Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj8AAAEQCAYAAABfvhVJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de7yNVf7A8e+Dco28HPfbya1IyuhCCpmKZtxChWgISeMSY0Ze4dg1jaRGo5BrkSIcl1wGyaUMDs5IQ0L9XDPRiVyGcnt+f2RWaz1z9rHPPnvvZ5+9Pu9/5rt8n7P3d9o2X89az1qO67oCAABgizx+FwAAABBLND8AAMAqND8AAMAqND8AAMAqND8AAMAq+bJzcVJSkpucnBylUnA1+/fvl4yMDCcSr8Vn6a9IfpYifJ5+47uZOPgsE0t6enqG67olvb+ereYnOTlZtm7dGrmqkC233357xF6Lz9JfkfwsRfg8/cZ3M3HwWSYWx3EOZPbrTHsBAACr0PwAAACr0PwAAACr0PwAAACr0PwAAACr0PwAAACr0PwAAACr0PwAAACr0PwAAACr0PwAAACr0PwAAACr0PwAAACrZOtgUwAAvIoVK6Zi7ynm27dvj3E1wNVx5wcAAFiF5gcAAFglIaa9Dh06ZIwff/xxFX/66adhvebAgQNV3K1bNyNXtWpVFRcsWDCs10fmjh8/HtJ18+bNM8b169dXcYUKFUJ+v1OnTql4woQJRi4tLU3Fb775ppGrWbOmivPmzRvy+9ngp59+UvFvfvMbI7d69WoVDx06VMV9+/Y1ritVqlSUqkM05Mnzy7+jz549a+TWr1+v4nvuuSdmNSG2evXqpeK5c+cauV27dqm4dOnSMaspK9z5AQAAVqH5AQAAVqH5AQAAVsm1a34OHDig4ubNmxu53bt3q7hhw4Yqvu2224zr3nvvPRU/9NBDRm7y5MkqHjNmjJGrW7euipcvX27kSpYsedXaYZo/f76KO3ToYOQuXLgQ63IyNWDAAGOcmpqq4qJFi8a6nLimr/lZs2aNkXMcR8UvvfSSij/66CPjOv33RLly5SJdIqLo66+/NsaNGjVS8eXLl2NdDmJkxowZKv7xxx+N3OnTp1XMmh8AAAAf0PwAAACr5JppL+/j7PpUlz7NJSJy7733qnjp0qUq1m+9iYj06NFDxd4psX379qn46aefNnL6LfpmzZoFzZUoUULwv7zbD3Tu3FnF3mmuypUrq7h169Yq3rRpU8Tr8j5e3bVrVxU3bdrUyDHVFVmbN282xl988YWKmfYCsu/EiRPGeO3atSr2bjkQ6eUaFStWNMZJSUkRff1I4M4PAACwCs0PAACwCs0PAACwSlyv+dm2bZuKH3vsMSP31VdfqVhf4yMismTJEhUXKVIk01hEpGzZskHf+4YbblDxsmXLjNz06dNVrK8bEjGPQUhJSQn6+jYbPXq0MT537pyKvf/NunfvrmLvPDLik37ch/eokcOHD4f0GvpRI/fff39kCgMs0r9/f2P87rvvqlhf/yMi0rhx44i+d5kyZYzx9ddfH9HXjwTu/AAAAKvQ/AAAAKvE1bSX9zHn1157TcV79+41ch07dlTxpEmTjJx3eiunvKd2P/nkkypevHixkRsxYoSKa9SoYeT0mm3Ts2dPFXt389X/Ow0ZMsTI5c+fP7qFIeIKFy6sYu8O6Pru6Fnt3r1nzx4VnzlzxshF+vsNJIq0tDQVe/9u0rcNueOOO2JWU7zizg8AALAKzQ8AALAKzQ8AALBKXK350ecrRUTef/99Fd93331G7q233lKxn2sAXnzxRWP88ccfq9h7Gny7du1UfO2110a3MJ8dPXrUGH/yyScq9p74O3jwYBWzxiex1KpVyxgXLFhQxVmt+dGPrPGuG2rfvn2EqgMSi76e8ocffjByd911l4oLFSoU8ffWH5ffuHGjkTt48KCKK1WqFPH3Dgd3fgAAgFVofgAAgFXiatorNTU1aM67W2W8nKpdu3ZtY6zfkn/nnXeMXHp6uoobNGgQ1br84Lquivv162fk9EeXvZo0aaLiNWvWGDnvCfDhePbZZ1UcL79vbBUIBFQ8YMCAoNfp3yumuYDQZHVqQbSnm9atW6di79IG/VSEYcOGRbWOUHHnBwAAWIXmBwAAWIXmBwAAWMX3NT/6sRXjxo0zcvrJsA899FDMasqJe+65R8XeNT/r169XcSKu+fn6669VPGfOnJB/rmrVqtEoR1m4cKGKt2zZYuS8R5cAQG7x5ZdfGuOhQ4cGvfaRRx6JdjlBdejQwbf3DoY7PwAAwCo0PwAAwCq+T3tdunRJxd4dX/UdKXPLjsj64956bIOMjIwcv0ZSUpIxzpfvl9+iXbp0UbH3pO+vvvpKxfpu0iIi27ZtU/GxY8eMXFaPhgJAPJsxY4Yx/vbbb1XsfbRd311dX4IhIpKcnKziChUqRLDCnzmOE/HXzCnu/AAAAKvQ/AAAAKv4Pu2lT1d4b435eWBpuPT/D/F4qy+avAdQBlOyZEljfOONN6rY+8Sf/nugSpUqIb3+8OHDjbF++GyzZs2M3IoVK1TMFFj0derUScUjR45UsXc6Up/W1G/li5hPgSI+XL58WcW2TffHmv706muvvRb0Ov0wURGRe++9N+i1119/vYr1J5FvvfVW4zr9gPG1a9caOX1X5wIFChi5eDywmjs/AADAKjQ/AADAKjQ/AADAKr6v+fniiy+C5po2bRrDSpBTvXr1UrH+eLmIucNnvXr1jFyNGjUiWkefPn2M8cmTJ1U8duxYI5eamhr05xB5+nqv3r17q1g/7V3EXAu4Zs0aI9exY8coVYdw5cnzy7+jbVvrGGuzZs1S8fnz542cvl6nSZMmQV9j69atxjgtLU3Ff//73zONRURefvnlkGqsX7++Ma5YsWJIPxdL3PkBAABWofkBAABW8X3aK9F4H8vVNW/ePIaVxJ7+qPiiRYt8q6NUqVLGuHLlykGvzWraFdGlP0br3cFdv52v3+YXYdorHumPNuvTzF7Tpk0zxk8++WTUakpUu3btUrF+CoKIOU1VrFixkF/zwIEDKv7mm29U7J1Wmzdvnoo//vhjI6cfslqzZs2Q39sv3PkBAABWofkBAABWofkBAABWias1P95t0T/88EMVd+vWLdblhESfKxURef7551XsPUrhlltuiUlNMOmP4D/33HNG7ujRo7EuB1e0adNGxd41Atu3b1fxZ599ZuQuXbqk4rx580apOmSHfsxC586dg17nfcSaNT/Zt2DBAhVfuHDByGVnnY9OXxeZ1RpJ/fF5vQ4RkbZt26r4uuuuC6uOWOLODwAAsArNDwAAsIrv017VqlVTcW7cGfTTTz8NmmvYsGEMK0Ew+m7T+pSJSNYnHSM+HD582BiPHz9exX379o11OchEuXLlVFy8eHEjd+LECRXv37/fyJ0+fVrFuWGqJB5UrVrV7xKuSt/2JF5x5wcAAFiF5gcAAFiF5gcAAFjF9zU/+gnfhQoVMnLxevSAPm89aNAgI1ekSBEV8xhnfPjLX/6i4suXLxu5nTt3xrocIOHoj0DffPPNRm79+vUq9p4Srm8VUrt27egUh6jI6iin3IA7PwAAwCo0PwAAwCq+T3vpu0m2atXKyM2ePVvFI0eONHJDhgyJbmEa/XFMEXO36WPHjhk5fRqsfPny0S0MmVq3bp0xXrNmTdBr9ZPF4Z86deoYY32HZ68dO3ZEuxwAV7F69Wq/S8gR7vwAAACr0PwAAACr0PwAAACr+L7mRxcIBIzxsmXLgub0xyJbtmwZ8VpOnTql4h49ehi5tWvXqtj7qPsrr7wS8Vpwdenp6SpOSUkxcj/++KOKb7rpJiPnXWcGf3hPAn/33XeDXjtjxgwVT5w4MWo1ITz6Ce8iInfddZdPlSDSXNdVsXctrC43/LnKnR8AAGAVmh8AAGCVuJr2ql69ujGePHmyih999FEj17FjRxVPnTrVyLVv317FefPmDem99+7da4y7d++u4i1bthi54cOHq3jo0KEhvb7tevfureJz584Zuf79+6tY3/FVxNwttnTp0ipeuXKlcd2wYcNU/OWXXwatY8WKFca4UqVKWZWNOOfdaqJUqVI+VYL/qlWrljFu06aNihcsWGDknnjiCRWPGjXKyD3wwANRqA45cfHiRRV7/yzV6ScdxCvu/AAAAKvQ/AAAAKvQ/AAAAKvE1Zofr0ceeUTF/fr1M3JvvPGGivX1PyLmmpzk5GQVex/N03Pz5s0zco7jqHjKlClGrkuXLlepHF67d+9Wsfe4iYULF6pY32JARKREiRIqLliwoIoPHToU8nv/7W9/U3HFihVD/jnEjvckcH28c+dOI/fTTz+peNq0aUbuueeei0J1yI7ChQsb42effVbFBQoUMHL6Ok/9z2Mg2rjzAwAArELzAwAArBLX014672OQ9913n4onTZpk5JYvX67iPXv2qFifyhIxH2/XH20XEenbt6+KvY9uIvtef/11FeuPpYuIfPjhh0F/LiMjI6TX13cI9u7wXKVKFRV7fw8gPpQrV84Y69/HgQMHGrl27dqpmGmu+NeoUaNMY+Q++tYxjz/+uJFbtWqVir3Tm/GIOz8AAMAqND8AAMAqND8AAMAquWbNj3cOUd8yXY8Rn+rUqaPiRYsW+VgJcgP98Wg9BuCfPHl+uV8yc+ZMHyvJOe78AAAAq9D8AAAAq9D8AAAAq9D8AAAAq9D8AAAAq9D8AAAAq9D8AAAAq9D8AAAAq9D8AAAAqziu64Z+seN8JyIHolcOrqKy67olI/FCfJa+i9hnKcLnGQf4biYOPsvEkunnma3mBwAAILdj2gsAAFiF5gcAAFgl15zqnhNOwGkuIn8TkbwiMsVNcV/2uSTkgBNw9ovIaRG5JCIX3RT3dn8rQricgDNNRFqIyDE3xa3tdz0IH59l4nECTl4R2Soi37gpbgu/64mkhL/zc+XDGyciD4lILRHp6AScWv5WhQi4z01xb6PxyfXeEZHmfheBiHhH+CwTTX8R2eV3EdGQ8M2PiNwpIl+5Ke7/uSnueRGZLSKtfa4JgIi4Ke4nInLc7zqQc3yWicUJOBVE5LciMsXvWqLBhuanvIgc0saHr/waci9XRFY6ASfdCThP+V0MACSg10XkTyJy2e9CosGG5sfJ5Nd4vj93a+imuL+Sn6cyf+8EnEZ+FwQAicIJOP9du5Xudy3RYkPzc1hEKmrjCiJyxKdaEAFuinvkyv8eE5EF8vPUJgAgMhqKSKsrD5fMFpGmTsCZ6W9JkWXD015bRKS6E3BuEJFvRKSDiHTytySEywk4hUUkj5vinr4SPygiL/hcFgAkDDfFHSIiQ0REnIDTREQGuSluZ1+LirCEv/PjprgXRaSPiKyQn1etz3FT3J3+VoUcKC0i652As11ENovIUjfFXe5zTQiTE3BmichGEbnRCTiHnYDT3e+aEB4+S+QmHG8BAACskvB3fgAAAHQ0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCo0PwAAwCr5snNxUlKSm5ycHKVScDX79++XjIwMJxKvxWfpr0h+liJ8nn7ju5k4+CwTS3p6eobruiW9v56t5ic5OVm2bt0auaqQLbfffnvEXovP0l+R/CxF+Dz9xnczcfBZJhbHcQ5k9utMewEAAKvQ/AAAAKvQ/AAAAKvQ/AAAAKvQ/AAAAKvQ/AAAAKvQ/AAAAKtka58fIDc4ffq0MW7SpImKhwwZYuTat28fi5IAAHGEOz8AAMAqND8AAMAqND8AAMAqrPlBQvj+++9V/PDDDxu548ePq7hEiRIxqwkAEJ+48wMAAKxC8wMAAKzCtBcSwlNPPaXif/zjH0bu8OHDKi5btmzMagJyu1OnTqn4/fffN3JbtmzJ9Gdq1KhhjLt27ari0qVLR644IAe48wMAAKxC8wMAAKxC8wMAAKzCmh/kSkuWLDHG//znP1U8YcIEI8c6H//Mnj3bGM+aNUvFixcvVrHrusZ1kydPVvETTzxh5K699tpIlmg9fZuIqVOnGrnx48er+ODBg2G9/uuvv67i66+/Puh13tzgwYNV3Lx5cyNXoECBsGpB9pw/f94Yr1y5UsWbNm0ycvqfyZ9//nnI73HTTTep+NNPPzVy0dyahDs/AADAKjQ/AADAKrl22uvixYsq7tOnj5HTb7lt3Lgx6Gvky/fL//1Vq1YZucaNG+e0RETYrl27VNyqVSsj161bNxXrj70j9vbu3aviIUOGGDl96sRxnKCv0atXr6DX6Y9O582bN9wyrZWWlmaMhw4dquKPP/7YyOnTkVl9XlnR/6yuWrWqkVu2bFnQn2vbtq2KmzVrZuTmzp2r4iJFioRVF35x9uxZFeu/B0aNGmVct2HDBhVn9fuhePHixrhgwYIq1qdZRUR2796t4jlz5hi53r17Z1V2jnDnBwAAWIXmBwAAWIXmBwAAWCXXrPnRT+YWMeepJ06cGNZr6nPRv/3tb42cvgaofv36Yb0+Iks/rb1JkyZG7pVXXolxNQhGX4+R1ePRI0eOVPG2bduMnD73713D9a9//UvF+mPUCO7IkSMq7tmzp5HbsWNHSK+RlJRkjPU1k88884yKveuG9O9mvXr1jNyJEydUfPLkSSPXrl07FS9fvtzIvfrqqyoeMWLE1UqHh/7IuojISy+9pOL169cH/Tn990CHDh2M3K9+9SsVe/98Tk5OVrF3Pa3+fvv27QtedIRx5wcAAFiF5gcAAFglrqe9PvvsMxW3bNnSyOkndUfCf/7zH2M8evRoFaempkb0vRCePXv2qPjPf/6zkYvmTqDInnPnzgXN6dPLgwYNCnrdmTNnVOx9HPqDDz5QMdNeodGnhrzTXPrOyrfccouRK1WqlIr1qSYRc5dl/bR2fUnC1ejfW+93WN/VWf+7QETkp59+Cvk98DN96rBTp05Gzjvl+F916tQxxvoO7frOzFezdu1aFX/55ZdBr4vlNiXc+QEAAFah+QEAAFah+QEAAFaJqzU///73v42xvs4n0mt8rkZ/nBb+SU9P97sEZJN+urOXfhxFnjzB/+3FsRU58/LLLxvjyZMnq7hu3bpGbvr06SoeM2aMkZs2bVoUqguN94RvXcOGDWNYSe40fPhwYzxhwgQVB1vjI2IeF/Xaa68ZOX17g6zoa/ZEzGNuMjIygv6c9+/5atWqhfR+4eDODwAAsArNDwAAsEpcTXt5b5VFYqqrfPnyKq5SpYqRy+q2KuLD0qVLVaxPheiP2SK+6CeBwx8LFiwwxvoJ3AMHDjRy5cqVU/GaNWuiW1gW9C0MRMzH27t162bk7rjjDhWfP3/eyF177bVRqC530B9n16e5RMxTEsqWLWvk3nrrLRU/+OCDKg51mkvE3C7m6aefNnKbN28O6TW8p8g3aNBAxfnz5w+5llBw5wcAAFiF5gcAAFiF5gcAAFglrtb8hKtMmTLGeNKkSSq++eabVexd86PPg3t16dIlQtUhO77//ntjrM9b649utmjRImY1IXv0tQVely5dUvHly5dV7F3vsWLFisgXZhHvGgv9z7qiRYsaOX0tRbNmzaJal/dYCv3P6j/96U9GTv9z3Xty++9+9zsVFytWzMi9++67Kk709T+nT582xi+88IKKvd9DfZ3P/Pnzjdydd96Z41qOHDmiYv0YjOzwbsOQ1XYYOcWdHwAAYBWaHwAAYJVcO+2l3xJduHChkbvrrrty/PorV65U8bBhw3L8egjN6tWrjbF+4vRjjz0W63IQhueff17FzzzzjJHTty7o3LmzimfPnm1cl9WUdFJSUk5LhKZIkSIq1h95jpSzZ8+qeOTIkUbupZdeCvpz+m7TlSpVMnL6tEqjRo2MXOPGjVW8cePG7BWby+h/T4mIpKWlBb1W/2wjMc3l9fnnn4d0XcWKFY3x+++/r2J9CwMRkWuuuSbnhQXBnR8AAGAVmh8AAGCVuJr28j6FkJycrOL9+/cbOX2Vu3dX0p07d2b6+qNHjw65lqNHj4Z8LaJHf0JBP/i2Ro0afpSDEPTo0UPF3kNOly1bpmLvE16hmjdvXniFWeTGG280xnv27FHx3r17I/5+q1atUnEgEDByp06dUnF2DozWa/YqXry4ivv162fkBgwYoOLU1FQj165du5DfP17pOym/+uqrQa/TTzcQEalVq1aO33vDhg0q9h6eG+ru4F27djXGd999d47rCgd3fgAAgFVofgAAgFVofgAAgFXias1P6dKljXHv3r1VPHjwYCOnz3sOGTIkuoUhqvRdXz/66CMjt3btWhXrc8pz5841rmvfvn10ikO25c2bV8Vvv/22kdPXg4wfPz6s1/c+Kov/1bBhQ2O8e/duFQ8aNMjI6Sd316tXz8gdO3ZMxd6T4mfOnJnjup588kkVd+rUycgVKFAgpNfUTyEXMXcFnj59upFLhDU/+hqqrE5LHzdunDH2nnCg03fS/+GHH1TsXVOk/7174cKFqxd7xR//+EcVx8vWMdz5AQAAVqH5AQAAVomraS+vP/zhDyrWH6UU+d/pkUg7ceKEinft2mXkatasGdX3to3+6O2cOXOMnL7Tr76zb/369aNfGHLMuxvzG2+8oWJ9ysN7cOXixYujWlei8z7+rU8f79u3z8jpj4Z7ua6rYu+u2/pY3yX61ltvNa6bMmWKim+44QYjF4mDRytXrmyM9eky71YLiUD/765PWYqYU1GtW7eO+Htn9ftB/657H4PXv+vxgjs/AADAKjQ/AADAKjQ/AADAKnG95kd/ZPaBBx4wclmd1nvmzJmQXr9gwYIqvnjxopHLyMhQsb5OQST8R3SRudq1a6v4hRdeMHL6egT986pQoUL0C0NU1a1bV8X6Cd4i5loN76PM+fPnj25hCcC77kZft7h8+XIjN3nyZBUvXbo06Gt6j5Tp06ePips3b67iatWqZa/YHNKPvREROX/+vIq964ESQZkyZVTs3W6gW7duKj537lxU6yhWrFjQ947HNT5e3PkBAABWofkBAABWietpL52+Q2RmY92MGTNUfPLkyaDX9e3bV8XeR0P1qS7vKdL67d5InJSLX+gngouIJCcnq1jfxdn7CGuLFi2iWhf8U6lSJWOsT4cjNPoj5a1atTJy+nRWVtNe3m0o6tSpE6HqckbfnVjE3DHee8J8onnkkUeMccmSJVW8f/9+I/fee++puEGDBkZO/294/PjxoO+nP94+duxYI9elS5erFxxHuPMDAACsQvMDAACsQvMDAACskmvW/GTHE088ke2f8W4Frp8G/N133xm5gwcPqpg1P5FVqFAhY6yvT9C3rfcef6BvhcCj0LnPhg0b/C4BVxFP3yv9EW/vmp9mzZqpOJy/C3KzJk2aBM117dpVxW+++aaRy2qdjy41NVXFbdq0yVZt8YY7PwAAwCo0PwAAwCoJOe0Vjl//+tfG+JlnnlGx94TaBQsWqFjf2RTRtXDhQhV7d/zWH3/2PnLpfawT8Sc9Pd3vEiDmqd3x5O233zbGAwcOVLH3pPjZs2fHpKZ4t2PHDmO8detWFQ8bNizoz5UvX17FnTt3NnK5fapLx50fAABgFZofAABgFZofAABgFdb8BKGfSutd8zN37lwV60dkiJgnlCOyGjZsqOKmTZsauYkTJ2Yai4jceeedKm7ZsqWR69Wrl4pLlCgRkTqB3ET/fV+9enUjt3fvXhWPGDHCyOnfs6JFi4b13vpRFKtXrzZyo0aNUvH27duNXJ48v/y7fdy4cUZO3xLDNqdOnVJx9+7djZy+5icrgwYNUrH32KdEwp0fAABgFZofAABgFaa9gihcuLCKy5QpY+S+/fZbFeunv4v875QLIkffYdb7OKv+KOzRo0eNnH4r+NChQ0buuuuui2SJ8Lhw4YIxvuaaazK9bsuWLcY4X75f/mh66qmnIl8YFP0k8FWrVhm5ypUrq/iDDz4wcuvWrVPxgw8+qOKHH3446Hvp01wiImPGjFFxWlpa0J+77bbbjLE+1WXzVhanT582xvouzqFOc4mIDB48WMW9e/fOcV25AXd+AACAVWh+AACAVWh+AACAVVjzE0S5cuVU3LNnTyP34osvqti7hgSx4X0sXX88E7G1efNmYzxlyhQVe7fY17caaNGihYq9p7rff//9Kq5Xr15E6sTVVapUyRjraxj79+9v5PS1jzNmzMg0FjGPzHAcx8jpj8h7j6Vp27ativWT2kXsfpxdt3LlSmO8aNGikH6udevWxvjZZ59VcbB1eYmGOz8AAMAqND8AAMAqTHuFoEePHsZYf6z6k08+MXKtWrVS8cyZM41cuLugAvHs66+/NsZTp04Neq3+OPPQoUODXlelSpWcF4Yc07cZuOOOO4zcuXPnVKxvVeCd6qxWrZqKvdNV+nTWTTfdlLNiLbFkyRIV64+2e+mns4uYSwO8j7PbMtWl484PAACwCs0PAACwCs0PAACwCmt+QuB9/FM/uX358uVGbvHixSo+duyYkWPNDxKR/vi6iMisWbNUvGnTJiM3f/58FevbRBQrVsy4rk+fPpEsERFQt27doLm77747hpXY7cyZMyo+e/Zs0Ou8p917v6e2484PAACwCs0PAACwCtNeYRg7dqyKhw0bZuT00+CLFy8es5oAvxQpUsQYP/roo5nGIiJ//etfY1ITkKg6dOiQaYzs4c4PAACwCs0PAACwCs0PAACwCmt+wlC9enUVz54928dKAABAdnHnBwAAWIXmBwAAWMVxXTf0ix3nOxE5EL1ycBWVXdctGYkX4rP0XcQ+SxE+zzjAdzNx8Fkmlkw/z2w1PwAAALkd014AAMAqND8AAMAqND8AAMAqVuzz4wSc/iLSU0QcEZnspodxDKsAAAH8SURBVLiv+1wSwuQEnGki0kJEjrkpbm2/60HO8N1MLE7AGSAiPUTEFZF/iUg3N8X90d+qEI5E/24m/J0fJ+DUlp8/wDtF5FYRaeEEnOpZ/xTi2Dsi0tzvIpBzfDcTixNwyotIPxG5/co/TPKKCCdv5kI2fDcTvvkRkZoisslNcc+6Ke5FEVknIg/7XBPC5Ka4n4jIcb/rQETw3Uw8+USkoBNw8olIIRE54nM9CE/CfzdtaH52iEgjJ+CUcAJOIRH5jYhU9LkmAHw3E4qb4n4jIq+KyEER+beInHRT3JX+VoUwJfx3M+GbHzfF3SUio0TkIxFZLiLbReSir0UB4LuZYJyAU1xEWovIDSJSTkQKOwGns79VIRw2fDetWPDsprhTRWSqiIgTcP4iIof9rQiACN/NBHO/iOxzU9zvREScgDNfRO4WkZm+VoWwJPp3M+Hv/IiIOAGn1JX/rSQibUVklr8VARDhu5lgDopIfSfgFHICjiMivxaRXT7XhDAl+nfTijs/IpLqBJwSInJBRH7vprgn/C4I4XECziwRaSIiSU7AOSwiKVf+hYLcie9mgnBT3DQn4MwTkX/Kz1Mk20Rkkr9VIQcS+rvJ2V4AAMAqVkx7AQAA/BfNDwAAsArNDwAAsArNDwAAsArNDwAAsArNDwAAsArNDwAAsMr/A4Dw/sq9yb/AAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = nn_utils.load_data()\n",
    "nn_utils.plot_random_examples(x_train, y_train).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in MNIST dataset there are 784 fetures\n",
    "it has 20 row and 20 columns for each example\n",
    "we will use two hidden layers with 128 units\n",
    "and we have 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rusla\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Input Features: 784\n",
      "Number of Classes: 10\n",
      "Hidden Layers:\n",
      "--------------\n",
      "Layer 1, Units 128\n",
      "Layer 2, Units 128\n",
      "--------------\n",
      "Number of parameters: 118282\n"
     ]
    }
   ],
   "source": [
    "net = NeuralNetwork([784,128,128,10])\n",
    "net.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch 500\n"
     ]
    }
   ],
   "source": [
    "batch_size = 120\n",
    "epochs = 5\n",
    "steps_per_epoch = int(x_train.shape[0]/batch_size)\n",
    "lr = 3e-3\n",
    "print('Steps per epoch', steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch0."
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only call `softmax_cross_entropy_with_logits` with named arguments (labels=..., logits=..., ...)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-48ed3aa60725>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     batch_size, lr)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-82657fbef19d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, x_train, y_train, x_test, y_test, epochs, steps_per_epoch, batch_size, lr)\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                 \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m                 \u001b[0mepoch_train_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-7713b33ceaa1>\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, X, Y, lr)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpersistent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-3f125b98d758>\u001b[0m in \u001b[0;36mcompute_loss\u001b[1;34m(self, A, Y)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# Your code here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36msoftmax_cross_entropy_with_logits\u001b[1;34m(_sentinel, labels, logits, dim, name)\u001b[0m\n\u001b[0;32m   2552\u001b[0m   \"\"\"\n\u001b[0;32m   2553\u001b[0m   _ensure_xent_args(\"softmax_cross_entropy_with_logits\", _sentinel, labels,\n\u001b[1;32m-> 2554\u001b[1;33m                     logits)\n\u001b[0m\u001b[0;32m   2555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2556\u001b[0m   with ops.name_scope(name, \"softmax_cross_entropy_with_logits_sg\",\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m_ensure_xent_args\u001b[1;34m(name, sentinel, labels, logits)\u001b[0m\n\u001b[0;32m   2313\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0msentinel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2314\u001b[0m     raise ValueError(\"Only call `%s` with \"\n\u001b[1;32m-> 2315\u001b[1;33m                      \"named arguments (labels=..., logits=..., ...)\" % name)\n\u001b[0m\u001b[0;32m   2316\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlogits\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2317\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Both labels and logits must be provided.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Only call `softmax_cross_entropy_with_logits` with named arguments (labels=..., logits=..., ...)"
     ]
    }
   ],
   "source": [
    "history = net.train(\n",
    "    x_train,y_train,\n",
    "    x_test, y_test,\n",
    "    epochs, steps_per_epoch,\n",
    "    batch_size, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 9: Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
